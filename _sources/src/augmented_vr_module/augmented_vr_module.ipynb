{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented VR Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from viper_toolkit import Dissect\n",
    "from scripts import augmented_vr\n",
    "from scripts.augmented_vr import AugmentedVRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class AugmentedVRModule(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.name = NameManager()\n",
      "        #self.dynamic_updates()\n",
      "        self.pose_estimations = InferenceResults()\n",
      "        self.setup_parameters()\n",
      "        self.setup_ros()\n",
      "        self.setup_scene_segmentation()\n",
      "        self.loop()\n",
      "\n",
      "    def setup_parameters(self):\n",
      "        # Adds all of our parameters to an updatable list. If ROS cannot\n",
      "        # find the parameter, it will use the default provided.\n",
      "        self.parameters = ParameterManager()\n",
      "        \n",
      "        self.parameters.add(Parameter(\"width\", \"/inland_ir_cam/width\", default = 800, dynamic = True))\n",
      "        self.parameters.add(Parameter(\"height\", \"/inland_ir_cam/height\", 600, True))\n",
      "        self.parameters.add(Parameter(\"updates\", f\"{self.name.name}/dynamic\", True, True))\n",
      "        self.parameters.add(Parameter(\"image_output\", f\"{self.name.name}/image_output\", True, True))\n",
      "        self.parameters.add(Parameter(\"alpha\", rospy.search_param('alpha'), 0.3, True))\n",
      "        self.parameters.add(Parameter(\"threshold\", rospy.search_param('threshold'), 0.1, True))\n",
      "        self.parameters.add(Parameter(\"segmentationmodel\", f\"{self.name.name}/segmentation\", True, True))\n",
      "        self.parameters.add(Parameter(\"posedetectionmodel\", f\"{self.name.name}/posedetection\", True, True))\n",
      "        self.parameters.add(Parameter(\"rate\", f\"{self.name.name}/rate\", 25, True))\n",
      "        \n",
      "    def setup_ros(self):\n",
      "        rospy.init_node('Augmented_VR', log_level = rospy.DEBUG)\n",
      "        self.bridge = CvBridge()\n",
      "        self.setup_camera()\n",
      "        self.setup_pose_detector()\n",
      "        self.setup_scene_segmentation()\n",
      "        self.setup_vr_publisher()\n",
      "        \n",
      "    def setup_vr_publisher(self):\n",
      "        self.pub = rospy.Publisher(\n",
      "            'Augmented_VR/stream',\n",
      "            Image,\n",
      "            queue_size=1\n",
      "            )\n",
      "            \n",
      "    def setup_camera(self):\n",
      "        rospy.Subscriber(\"image_server/image\",\n",
      "            Image, \n",
      "            self.image_callback, \n",
      "            queue_size=1\n",
      "            )\n",
      "        rospy.loginfo(\"Camera Online\")\n",
      "\n",
      "        self.image = Image()\n",
      "        self.new_image = True\n",
      "\n",
      "        self.canvas = np.zeros((\n",
      "                    self.parameters.height,\n",
      "                    self.parameters.width, \n",
      "                    3\n",
      "                    ), dtype = \"uint8\"\n",
      "                    )\n",
      "\n",
      "    def setup_pose_detector(self):\n",
      "        rospy.Subscriber(\n",
      "            'model_output/pose_articulator/human_graph_nodes',\n",
      "            InferenceResults,\n",
      "            self.pose_estimation_callback,\n",
      "            queue_size=1\n",
      "            )\n",
      "        self.pose_estimations = InferenceResults()\n",
      "        self.new_graph = True\n",
      "        self.graph = []\n",
      "        rospy.loginfo(\"Pose detector subscription active\")\n",
      "\n",
      "    def setup_scene_segmentation(self):\n",
      "        self.mask = InferenceResults()\n",
      "        self.new_mask = True\n",
      "        rospy.Subscriber(\n",
      "            'model_output/scene_segmentation/segmentation_mask',\n",
      "            InferenceResults,\n",
      "            self.scene_segmentation_callback,\n",
      "            queue_size=1\n",
      "            )\n",
      "        self.mask = InferenceResults()\n",
      "        self.colormap = np.array([[68, 1, 84], [48, 103, 141], [53, 183, 120], [199, 216, 52]])\n",
      "        rospy.loginfo(\"Scene Segmentation subscription active\")\n",
      "\n",
      "    def pose_estimation_callback(self, msg):\n",
      "        self.pose_estimations = msg\n",
      "        self.new_graph = True\n",
      "        print (self.pose_estimations)\n",
      "        rospy.loginfo(\"[POS] New Coordinates Received\")\n",
      "\n",
      "    def scene_segmentation_callback(self, msg):\n",
      "        self.mask = msg\n",
      "        self.new_mask = True\n",
      "        print (self.mask)\n",
      "        rospy.loginfo(\"[SEG] New Masks Received\")\n",
      "   \n",
      "    def image_callback(self, msg):\n",
      "        self.image = msg\n",
      "        self.new_image = True\n",
      "        rospy.loginfo(\"[IMG] New Image Received\")\n",
      "\n",
      "    def decode_inference_results(self, results, model: str = None):\n",
      "        if model == None:\n",
      "            name = self.name.abv\n",
      "        else:\n",
      "            name = model\n",
      "        self.timer.lap(\"Decode Inference\")\n",
      "        rospy.logdebug(f\"Decoding {name}\")\n",
      "        try:\n",
      "            structure = results.structure\n",
      "            print(name, structure)\n",
      "        except:\n",
      "            rospy.logerr(\n",
      "            f\"[{name}] Cannot convert {type(self.results.structure)} to structure\"\n",
      "            )\n",
      "            return\n",
      "        print (\"------------------------------------------\")\n",
      "        try:\n",
      "            inferences = np.asarray(results.inferences)\n",
      "            print(inferences)\n",
      "            rospy.loginfo(f\"[{name}] Transformed shape: {inferences.shape}\")\n",
      "        except:\n",
      "            rospy.logerr(f'[{name}] Cannot convert to numpy array')\n",
      "            return\n",
      "            \n",
      "        try:\n",
      "            inference_array = inferences.reshape(results.structure)\n",
      "            print(inference_array)\n",
      "        except:\n",
      "            rospy.logerr(f\"[{name}] Cannot wrangle data blob\")\n",
      "            return\n",
      "            \n",
      "        #self.timer.time(\"Decode Inference\", name=name)\n",
      "        \n",
      "        return inference_array\n",
      "            \n",
      "    def update_segmentation_graph(self):\n",
      "    # This function tasks a message file (self.mask) and decodes it into\n",
      "    # the original array, outputing the \"segmentation graph\". Note that\n",
      "    # this output can be used on its own as an image.\n",
      "        print (self.mask)\n",
      "        #self.timer.lap(\"Segmentation Process\")\n",
      "        #try:\n",
      "        inference_array = self.decode_inference_results(\n",
      "                self.mask, \n",
      "                model=\"SEG\"\n",
      "                )\n",
      "        #rospy.loginfo(f'inference_array is: {type(inference_array)} {inference_array.shape}')\n",
      "        #except:\n",
      "        #    rospy.logerr(f\"[SEG] Cannot decode results\")\n",
      "        #    return\n",
      "        \n",
      "        #try:\n",
      "            #self.timer.lap(\"Segmentation Model\")\n",
      "            #rospy.logdebug(f\"[{self.name.abv}] Conversion Shape: %s\",inference_array.shape)\n",
      "        print(type(inference_array))\n",
      "        mask = segmentation_map_to_image(inference_array, self.colormap)\n",
      "            #rospy.logdebug(f\"[{self.name.abv}] Resizing Mask\")\n",
      "        self.segmentation_graph = cv2.resize(inference_array, (self.image.width, self.image.height))\n",
      "        self.logdebug(f'seg graph shape {self.segmentation_graph.shape}')\n",
      "            #rospy.logdebug(f\"[{self.name.abv}] Masking Image\")\n",
      "            #self.timer.time(\"Segmentation Model\", name=\"SEG\")\n",
      "            #self.timer.time(\"Segmentation Process\", name=\"SEG\")\n",
      "        return\n",
      "        #except:\n",
      "        #    rospy.logerr(f\"[SEG] Cannot resize mask at point A\")\n",
      "            #self.timer.time(\"Segmentation Model\", name=\"SEG\")\n",
      "            #self.timer.time(\"Segmentation Process\", name=\"SEG\")\n",
      "        #    return\n",
      "\n",
      "    def combine_segmentation_image(self):\n",
      "        # This function combines the current segmentation_graph \n",
      "        # and the current converted image, and saves it as the \n",
      "        # current output (canvas)\n",
      "        alpha = 0.3\n",
      "        self.timer.lap(\"Image Overlay\")\n",
      "        #try:\n",
      "        self.canvas = cv2.addWeighted(\n",
      "            self.segmentation_graph, \n",
      "            alpha, #self.parameters.alpha, \n",
      "            self.img, \n",
      "            1 - alpha, \n",
      "            0)\n",
      "        #except:\n",
      "        #    rospy.logerr(f\"[SEG] Cannot combine mask and image at B\")\n",
      "            \n",
      "        # Regardless of success we will update our timer.\n",
      "        #self.timer.time(\"Image Overlay\", name = \"SEG\")\n",
      "        return \n",
      "\n",
      "    def calculate_pose_graph(self):\n",
      "        # This process takes the current pose estimation msg\n",
      "        # (self.pose_estimates) and converts them to the \n",
      "        # pose graph nodes and edges. It then saves these\n",
      "        # to the current nodes and edges (self.graph)\n",
      "\n",
      "        # Convert the message arrays\n",
      "        #self.timer.lap(\"Graph Nodes Edges\")\n",
      "        rospy.logdebug(\"Decoding Pose Graph Results\")\n",
      "        #try:\n",
      "        self.graph = self.decode_inference_results(\n",
      "            self.pose_estimations, \n",
      "            model=\"POS\"\n",
      "            )\n",
      "        #except:\n",
      "            # If this fails there is nothing to return.\n",
      "        #    rospy.logerr(f\"[POS] Cannot decode results\")\n",
      "            \n",
      "        #self.timer.time(\"Graph Nodes Edges\")\n",
      "\n",
      "    def draw_graph(self):\n",
      "        # Draw the Poses on the provided image 'image' and return\n",
      "        # the composite 'graph'\n",
      "        self.timer.lap(\"Draw Poses\")\n",
      "        try:\n",
      "            self.canvas = draw_poses(\n",
      "                img = self.canvas, \n",
      "                poses = self.graph, \n",
      "                point_score_threshold = 0.1) #elf.parameters.threshold\n",
      "\n",
      "        except:\n",
      "            rospy.logerr(f\"[POS] Cannot draw Poses\")\n",
      "        self.timer.time(\"Draw Poses\", name=\"POS\")\n",
      "\n",
      "    def action_loop(self):\n",
      "\n",
      "        # First, we need to decide if we are using an existing \n",
      "        # segmentation mask, or creating a new segmentation. If there\n",
      "        # are new masks, we will update the self.segmentation_graph\n",
      "        # and then remove our flag since we can use this until the new\n",
      "        # results are delivered.\n",
      "        if self.new_mask:\n",
      "            self.update_segmentation_graph()\n",
      "            self.new_mask = False\n",
      "        \n",
      "        # Next we will decide if we are recalculating the existing\n",
      "        # graph nodes at self.graph.\n",
      "        if self.new_graph:\n",
      "            self.calculate_pose_graph()\n",
      "            self.new_graph = False\n",
      "        \n",
      "        # If we are combining the segmentation and the images, then we\n",
      "        # first need to mask the new images, but we only need to do\n",
      "        # this if we need to combine the images and the inferences.\n",
      "        temp = True\n",
      "        if temp: #self.parameters.image_output:\n",
      "            if self.new_image:\n",
      "                try:\n",
      "                    # Convert the camera image to ROS\n",
      "                    self.img = self.bridge.imgmsg_to_cv2(\n",
      "                        self.image, \n",
      "                        desired_encoding=\"bgr8\"\n",
      "                        )\n",
      "                    self.new_graph = False\n",
      "                except CvBridgeError as e:\n",
      "                    # if this fails then give us the last good image.\n",
      "                    rospy.logerr(\"[IMG] Error converting ROS msg to image.\")\n",
      "                    print(e)\n",
      "                    \n",
      "            if temp: #self.parameters.segmentationmodel:\n",
      "                try:\n",
      "                    # We can now combine them on the 'self.canvas' layer.\n",
      "                    self.combine_segmentation_image()\n",
      "                except:\n",
      "                    rospy.logerr(\"[SEG] Error proccessing scene\")\n",
      "        else:\n",
      "            if self.parameters.segmentation_model:\n",
      "            # If we are not using the camera image output then we\n",
      "            # will just replace the self.image with the segmentation\n",
      "            # graph image.\n",
      "            \n",
      "                self.canvas = self.segmentation_graph\n",
      "            else:\n",
      "                self.canvas = np.zeros((\n",
      "                    self.height, \n",
      "                    self.width, \n",
      "                    3\n",
      "                    ), dtype = \"uint8\"\n",
      "                    )\n",
      "            \n",
      "        # Next we will draw our the current pose graph nodes and edges\n",
      "        # onto our canvas\n",
      "        \n",
      "        #if self.parameters.posedetectionmodel == True:\n",
      "        try:\n",
      "            self.draw_graph()\n",
      "        except:\n",
      "            rospy.logerr(\"[POS] Error drawing pose detection graph\")\n",
      "\n",
      "        # Finally we will convert our image canvase back to the \n",
      "        # ROS message format.\n",
      "        try:\n",
      "            image_ros = self.bridge.cv2_to_imgmsg(self.canvas, 'bgr8')\n",
      "            return image_ros\n",
      "                \n",
      "        except (CvBridgeError, TypeError, UnboundLocalError) as e:\n",
      "            # If this conversion failes we will simply provide the last\n",
      "            # good ROS image message since sometimes packages are lost\n",
      "            rospy.logerr(\"[IMG]Error converting to ROS msg\")\n",
      "            print (e)\n",
      "            return self.image\n",
      "\n",
      "    def loop(self):\n",
      "\n",
      "        rate = rospy.Rate(self.parameters.rate)\n",
      "        while not rospy.is_shutdown():  \n",
      "            # We have created a parameter for dynamically updateding an\n",
      "            # active node. These will update if the global value changes\n",
      "            #if self.parameters.updates == True:\n",
      "            #    self.parameters.update()\n",
      "            self.timer = ProcessTimer(abv = self.name.abv)\n",
      "            ros_image = self.action_loop()\n",
      "            self.pub.publish(ros_image)\n",
      "            rate.sleep()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = inspect.getsource(AugmentedVRModule)\n",
    "print (source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented VR Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from viper_toolkit import Dissect\n",
    "from scripts import augmented_vr\n",
    "from scripts.augmented_vr import AugmentedVRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class AugmentedVRModule(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.name = NameManager()\n",
      "        #self.dynamic_updates()\n",
      "        self.pose_estimations = InferenceResults()\n",
      "        self.setup_parameters()\n",
      "        self.setup_ros()\n",
      "        self.setup_scene_segmentation()\n",
      "        self.loop()\n",
      "\n",
      "    def setup_parameters(self):\n",
      "        # Adds all of our parameters to an updatable list. If ROS cannot\n",
      "        # find the parameter, it will use the default provided.\n",
      "        self.parameters = ParameterManager()\n",
      "        \n",
      "        self.parameters.add(Parameter(\"width\", \"/inland_ir_cam/width\", default = 800, dynamic = True))\n",
      "        self.parameters.add(Parameter(\"height\", \"/inland_ir_cam/height\", 600, True))\n",
      "        self.parameters.add(Parameter(\"updates\", f\"{self.name.name}/dynamic\", True, True))\n",
      "        self.parameters.add(Parameter(\"image_output\", f\"{self.name.name}/image_output\", True, True))\n",
      "        self.parameters.add(Parameter(\"alpha\", rospy.search_param('alpha'), 0.3, True))\n",
      "        self.parameters.add(Parameter(\"threshold\", rospy.search_param('threshold'), 0.1, True))\n",
      "        self.parameters.add(Parameter(\"segmentationmodel\", f\"{self.name.name}/segmentation\", True, True))\n",
      "        self.parameters.add(Parameter(\"posedetectionmodel\", f\"{self.name.name}/posedetection\", True, True))\n",
      "        self.parameters.add(Parameter(\"rate\", f\"{self.name.name}/rate\", 25, True))\n",
      "        \n",
      "    def setup_ros(self):\n",
      "        rospy.init_node('Augmented_VR', log_level = rospy.DEBUG)\n",
      "        self.bridge = CvBridge()\n",
      "        self.setup_camera()\n",
      "        self.setup_pose_detector()\n",
      "        self.setup_scene_segmentation()\n",
      "        self.setup_vr_publisher()\n",
      "        \n",
      "    def setup_vr_publisher(self):\n",
      "        self.pub = rospy.Publisher(\n",
      "            'Augmented_VR/stream',\n",
      "            Image,\n",
      "            queue_size=1\n",
      "            )\n",
      "            \n",
      "    def setup_camera(self):\n",
      "        rospy.Subscriber(\"image_server/image\",\n",
      "            Image, \n",
      "            self.image_callback, \n",
      "            queue_size=1\n",
      "            )\n",
      "        rospy.loginfo(\"Camera Online\")\n",
      "\n",
      "        self.image = Image()\n",
      "        self.new_image = True\n",
      "\n",
      "        self.canvas = np.zeros((\n",
      "                    self.parameters.height,\n",
      "                    self.parameters.width, \n",
      "                    3\n",
      "                    ), dtype = \"uint8\"\n",
      "                    )\n",
      "\n",
      "    def setup_pose_detector(self):\n",
      "        rospy.Subscriber(\n",
      "            'model_output/pose_articulator/human_graph_nodes',\n",
      "            InferenceResults,\n",
      "            self.pose_estimation_callback,\n",
      "            queue_size=1\n",
      "            )\n",
      "        self.pose_estimations = InferenceResults()\n",
      "        self.new_graph = True\n",
      "        self.graph = []\n",
      "        rospy.loginfo(\"Pose detector subscription active\")\n",
      "\n",
      "    def setup_scene_segmentation(self):\n",
      "        self.mask = InferenceResults()\n",
      "        self.new_mask = True\n",
      "        rospy.Subscriber(\n",
      "            'model_output/scene_segmentation/segmentation_mask',\n",
      "            InferenceResults,\n",
      "            self.scene_segmentation_callback,\n",
      "            queue_size=1\n",
      "            )\n",
      "        self.mask = InferenceResults()\n",
      "        self.colormap = np.array([[68, 1, 84], [48, 103, 141], [53, 183, 120], [199, 216, 52]])\n",
      "        rospy.loginfo(\"Scene Segmentation subscription active\")\n",
      "\n",
      "    def pose_estimation_callback(self, msg):\n",
      "        self.pose_estimations = msg\n",
      "        self.new_graph = True\n",
      "        print (self.pose_estimations)\n",
      "        rospy.loginfo(\"[POS] New Coordinates Received\")\n",
      "\n",
      "    def scene_segmentation_callback(self, msg):\n",
      "        self.mask = msg\n",
      "        self.new_mask = True\n",
      "        rospy.loginfo(\"[SEG] New Masks Received\")\n",
      "   \n",
      "    def image_callback(self, msg):\n",
      "        self.image = msg\n",
      "        self.new_image = True\n",
      "        rospy.loginfo(\"[IMG] New Image Received\")\n",
      "\n",
      "    def decode_inference_results(self, results, model: str = None):\n",
      "        if model == None:\n",
      "            name = self.name.abv\n",
      "        else:\n",
      "            name = model\n",
      "        self.timer.lap(\"Decode Inference\")\n",
      "        rospy.logdebug(f\"Decoding {name}\")\n",
      "        try:\n",
      "            structure = results.structure\n",
      "            print(name, structure)\n",
      "        except:\n",
      "            rospy.logerr(\n",
      "            f\"[{name}] Cannot convert {type(self.results.structure)} to structure\"\n",
      "            )\n",
      "            return\n",
      "        print (\"------------------------------------------\")\n",
      "        try:\n",
      "            inferences = np.asarray(results.inferences)\n",
      "            print(inferences)\n",
      "            rospy.loginfo(f\"[{name}] Transformed shape: {inferences.shape}\")\n",
      "        except:\n",
      "            rospy.logerr(f'[{name}] Cannot convert to numpy array')\n",
      "            return\n",
      "            \n",
      "        try:\n",
      "            inference_array = inferences.reshape(results.structure)\n",
      "            print(inference_array)\n",
      "        except:\n",
      "            rospy.logerr(f\"[{name}] Cannot wrangle data blob\")\n",
      "            return\n",
      "            \n",
      "        #self.timer.time(\"Decode Inference\", name=name)\n",
      "        \n",
      "        return inference_array\n",
      "            \n",
      "    def update_segmentation_graph(self):\n",
      "    # This function tasks a message file (self.mask) and decodes it into\n",
      "    # the original array, outputing the \"segmentation graph\". Note that\n",
      "    # this output can be used on its own as an image.\n",
      "    \n",
      "        self.timer.lap(\"Segmentation Process\")\n",
      "        try:\n",
      "            inference_array = self.decode_inference_results(\n",
      "                self.mask, \n",
      "                model=\"SEG\"\n",
      "                )\n",
      "        except:\n",
      "            #rospy.logerr(f\"[SEG] Cannot decode results\")\n",
      "            return\n",
      "        \n",
      "        try:\n",
      "            #self.timer.lap(\"Segmentation Model\")\n",
      "            #rospy.logdebug(f\"[{self.name.abv}] Conversion Shape: %s\",inference_array.shape)\n",
      "            mask = segmentation_map_to_image(inference_array, self.colormap)\n",
      "            #rospy.logdebug(f\"[{self.name.abv}] Resizing Mask\")\n",
      "            self.segmentation_graph = cv2.resize(inference_array, (self.image.width, self.image.height))\n",
      "            #rospy.logdebug(f\"[{self.name.abv}] Masking Image\")\n",
      "            #self.timer.time(\"Segmentation Model\", name=\"SEG\")\n",
      "            #self.timer.time(\"Segmentation Process\", name=\"SEG\")\n",
      "            return\n",
      "        except:\n",
      "            #rospy.logerr(f\"[SEG] Cannot resize mask\")\n",
      "            #self.timer.time(\"Segmentation Model\", name=\"SEG\")\n",
      "            #self.timer.time(\"Segmentation Process\", name=\"SEG\")\n",
      "            return\n",
      "\n",
      "    def combine_segmentation_image(self):\n",
      "        # This function combines the current segmentation_graph \n",
      "        # and the current converted image, and saves it as the \n",
      "        # current output (canvas)\n",
      "        \n",
      "        self.timer.lap(\"Image Overlay\")\n",
      "        try:\n",
      "            self.canvas = cv2.addWeighted(\n",
      "                self.segmentation_graph, \n",
      "                self.parameters.alpha, \n",
      "                self.img, \n",
      "                1 - self.parameters.alpha, \n",
      "                0)\n",
      "        except:\n",
      "            rospy.logerr(f\"[SEG] Cannot combine mask and image\")\n",
      "            \n",
      "        # Regardless of success we will update our timer.\n",
      "        self.timer.time(\"Image Overlay\", name = \"SEG\")\n",
      "        return \n",
      "\n",
      "    def calculate_pose_graph(self):\n",
      "        # This process takes the current pose estimation msg\n",
      "        # (self.pose_estimates) and converts them to the \n",
      "        # pose graph nodes and edges. It then saves these\n",
      "        # to the current nodes and edges (self.graph)\n",
      "\n",
      "        # Convert the message arrays\n",
      "        self.timer.lap(\"Graph Nodes Edges\")\n",
      "        rospy.logdebug(\"Decoding Pose Graph Results\")\n",
      "        #try:\n",
      "        self.graph = self.decode_inference_results(\n",
      "            self.pose_estimations, \n",
      "            model=\"POS\"\n",
      "            )\n",
      "        #except:\n",
      "            # If this fails there is nothing to return.\n",
      "        #    rospy.logerr(f\"[POS] Cannot decode results\")\n",
      "            \n",
      "        self.timer.time(\"Graph Nodes Edges\")\n",
      "\n",
      "    def draw_graph(self):\n",
      "        # Draw the Poses on the provided image 'image' and return\n",
      "        # the composite 'graph'\n",
      "        self.timer.lap(\"Draw Poses\")\n",
      "        try:\n",
      "            self.canvas = draw_poses(\n",
      "                img = self.canvas, \n",
      "                poses = self.graph, \n",
      "                point_score_threshold = 0.1) #elf.parameters.threshold\n",
      "\n",
      "        except:\n",
      "            rospy.logerr(f\"[POS] Cannot draw Poses\")\n",
      "        self.timer.time(\"Draw Poses\", name=\"POS\")\n",
      "\n",
      "    def action_loop(self):\n",
      "\n",
      "        # First, we need to decide if we are using an existing \n",
      "        # segmentation mask, or creating a new segmentation. If there\n",
      "        # are new masks, we will update the self.segmentation_graph\n",
      "        # and then remove our flag since we can use this until the new\n",
      "        # results are delivered.\n",
      "        if self.new_mask:\n",
      "            self.update_segmentation_graph()\n",
      "            self.new_mask = False\n",
      "        \n",
      "        # Next we will decide if we are recalculating the existing\n",
      "        # graph nodes at self.graph.\n",
      "        if self.new_graph:\n",
      "            self.calculate_pose_graph()\n",
      "            self.new_graph = False\n",
      "        \n",
      "        # If we are combining the segmentation and the images, then we\n",
      "        # first need to mask the new images, but we only need to do\n",
      "        # this if we need to combine the images and the inferences.\n",
      "\n",
      "        if self.parameters.image_output == True:\n",
      "            if self.new_image == True:\n",
      "                try:\n",
      "                    # Convert the camera image to ROS\n",
      "                    self.img = self.bridge.imgmsg_to_cv2(\n",
      "                        self.image, \n",
      "                        desired_encoding=\"bgr8\"\n",
      "                        )\n",
      "                    self.new_graph = False\n",
      "                except CvBridgeError as e:\n",
      "                    # if this fails then give us the last good image.\n",
      "                    rospy.logerr(\"[IMG] Error converting ROS msg to image.\")\n",
      "                    print(e)\n",
      "                    \n",
      "            if self.parameters.segmentationmodel == True:\n",
      "                try:\n",
      "                    # We can now combine them on the 'self.canvas' layer.\n",
      "                    self.combine_segmentation_image()\n",
      "                except:\n",
      "                    rospy.logerr(\"[SEG] Error proccessing scene\")\n",
      "        else:\n",
      "            if self.parameters.segmentation_model == True:\n",
      "            # If we are not using the camera image output then we\n",
      "            # will just replace the self.image with the segmentation\n",
      "            # graph image.\n",
      "            \n",
      "                self.canvas = self.segmentation_graph\n",
      "            else:\n",
      "                self.canvas = np.zeros((\n",
      "                    self.height, \n",
      "                    self.width, \n",
      "                    3\n",
      "                    ), dtype = \"uint8\"\n",
      "                    )\n",
      "            \n",
      "        # Next we will draw our the current pose graph nodes and edges\n",
      "        # onto our canvas\n",
      "        \n",
      "        #if self.parameters.posedetectionmodel == True:\n",
      "        try:\n",
      "            self.draw_graph()\n",
      "        except:\n",
      "            rospy.logerr(\"[POS] Error drawing pose detection graph\")\n",
      "\n",
      "        # Finally we will convert our image canvase back to the \n",
      "        # ROS message format.\n",
      "        try:\n",
      "            image_ros = self.bridge.cv2_to_imgmsg(self.canvas, 'bgr8')\n",
      "            return image_ros\n",
      "                \n",
      "        except (CvBridgeError, TypeError, UnboundLocalError) as e:\n",
      "            # If this conversion failes we will simply provide the last\n",
      "            # good ROS image message since sometimes packages are lost\n",
      "            rospy.logerr(\"[IMG]Error converting to ROS msg\")\n",
      "            print (e)\n",
      "            return self.image\n",
      "\n",
      "    def loop(self):\n",
      "\n",
      "        rate = rospy.Rate(self.parameters.rate)\n",
      "        while not rospy.is_shutdown():  \n",
      "            # We have created a parameter for dynamically updateding an\n",
      "            # active node. These will update if the global value changes\n",
      "            #if self.parameters.updates == True:\n",
      "            #    self.parameters.update()\n",
      "            self.timer = ProcessTimer(abv = self.name.abv)\n",
      "            ros_image = self.action_loop()\n",
      "            self.pub.publish(ros_image)\n",
      "            rate.sleep()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = inspect.getsource(AugmentedVRModule)\n",
    "print (source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scene Segmentation Module is a ROS Package Module which is comprised of:\n",
    "\n",
    "* the SceneSegmentationModule Class Object\n",
    "* the SceneSegmentationModel processing library\n",
    "* the RoadSegmentation ADAS Model and pretrained weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the SceneSegmentationModule Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class loads a NameManager, the InferenceResults() message type, and the setup functions upon initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SceneSegmentationModule(object):\n",
      "\n",
      "    def __init__(self):\n",
      "        self.name = NameManager(abv=\"SEG\")\n",
      "        self.inference = InferenceResults()\n",
      "        self.setup_ros()\n",
      "        #self.setup_model()\n",
      "        self.loop()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dissect(\"__init__\", SceneSegmentationModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Paramters\n",
    "We initalize several parameters with the parameter server, including the rate at which we would like the node to run, as well as if we would like to be able to dynamically update this node. This will allow us to change its rate once it is already running to optimize its performance with the other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SceneSegmentationModule(object):\n",
      "\n",
      "    def setup_parameters(self):\n",
      "        self.parameters = ParameterManager()\n",
      "        self.parameters.add(Parameter(\n",
      "            name=\"rate\", \n",
      "            target=f\"{self.name.name}/rate\", \n",
      "            default=50, \n",
      "            dynamic=True\n",
      "            ))\n",
      "        self.parameters.add(Parameter(\n",
      "            name=\"updates\", \n",
      "            target=f\"{self.name.name}/dynamic\", \n",
      "            default=True, \n",
      "            dynamic=True\n",
      "            ))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dissect(\"setup_parameters\", SceneSegmentationModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up ROS and the Model Server\n",
    " We setup the module and register it with the ROS network. We also setup the **model_server/modeling_service** ServiceProxy which we will use to request new Models. The request message 'ModelRequest' takes the name of a model (SEG is the name of the Segmentation model) and returns an Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SceneSegmentationModule(object):\n",
      "\n",
      "    def setup_ros(self):\n",
      "        self.setup_parameters()\n",
      "        rospy.init_node('scene_segmentation', log_level=rospy.DEBUG)\n",
      "        self.setup_model_server()\n",
      "        self.image_server = ImageServerClient(self.name.abv)\n",
      "\n",
      "class SceneSegmentationModule(object):\n",
      "\n",
      "    def setup_model_server(self):\n",
      "        \n",
      "        self.model_request = rospy.ServiceProxy(\n",
      "            'model_server/modeling_service',\n",
      "            ModelRequest,\n",
      "            )\n",
      "\n",
      "        self.pub = rospy.Publisher(\n",
      "            'model_output/scene_segmentation/segmentation_mask',\n",
      "            InferenceResults,\n",
      "            queue_size=1\n",
      "            )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dissect(\"setup_ros\", SceneSegmentationModule)\n",
    "Dissect(\"setup_model_server\", SceneSegmentationModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageServerClient\n",
    "We also configure the Image Server client, which allows this module to communicate with the image server. It does this much in the same way that a Publisher publishes messages... when the module is ready for a new image it broadcasts that it is waiting for an image. The image server is a subscriber of these broadcasts, and once it hears this message it will provide an image to the model server.\n",
    "\n",
    "The reason we have chosen this method rather than providing a service is that a service call blocks the kernel from processing more code until the call has completed and a response has been received, whereas a publisher will simply continue to broadcast a message, regardless if it is received or not. This ensures that processes are not tied up in a service call. \n",
    "\n",
    "Once the Image Server hears that the client is in need of an image it begins the process and communicates to all nodes after it has updated the model server with the new image. It then changes these nodes \"waiting\" status to false via the ImageServerClient.callback. This ensures that while the module is engaging the model server the image server does not wastefully deliver images which no module will use, potentially reducing bandwidth by nearly 87% (assuming that an request is made twice a second, and the image server is reciving images at the rate of 16 FPS; since only two of those frames out of 16 can be used, only two will be delivered to the model server which would otherwise receive all 16!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ImageServerClient(object):\n",
      "    def __init__(self, name: str):\n",
      "        self._name = name\n",
      "        self.waiting = Bool()\n",
      "        self.remote_status = Bool()\n",
      "        self.setup_publisher()\n",
      "        self.setup_subscriber()\n",
      "        \n",
      "    def setup_publisher(self):\n",
      "        self.pub = rospy.Publisher(\n",
      "            f'image_request/{self._name}',\n",
      "            Bool,\n",
      "            queue_size=1\n",
      "            )\n",
      "        rospy.loginfo(\n",
      "            f'[{self._name}] Image server request services online.'\n",
      "            )\n",
      "            \n",
      "    def update(self, state: bool):\n",
      "        self.waiting.data = state\n",
      "        self.pub.publish(self.waiting)\n",
      "   \n",
      "    def status(self, entity = \"server\"):\n",
      "        if entity == \"server\":\n",
      "            return self.remote_status.data\n",
      "        else:\n",
      "            return self.waiting.data\n",
      "    \n",
      "    def refresh(self, state: bool):\n",
      "        self.waiting.data = state\n",
      "        \n",
      "    def setup_subscriber(self):\n",
      "        rospy.Subscriber(\n",
      "            'image_server/status',\n",
      "            Bool,\n",
      "            self.callback,\n",
      "            queue_size=1\n",
      "            )\n",
      "        rospy.loginfo(\n",
      "            f'[{self._name}] Subscribed to Image Server.'\n",
      "            )\n",
      "\n",
      "    def callback(self, msg):\n",
      "        self.remote_status = msg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from image_server import ImageServerClient\n",
    "print (inspect.getsource(ImageServerClient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Loop\n",
    "When the SceneSegmentationModule is ready to perform inference it contacts the model server and provides its modeling code \"SEG\". The model server then computes the inference, and returns an inference message.\n",
    "\n",
    "Inference Messages contain two variables:\n",
    "* int32[]     structure\n",
    "* float32[]   inferences\n",
    "\n",
    "The Vision Processing Unit computes the segmentation of the image, and produces an array of variable length indicating the class of each pixel in the image. All ROS messages must be compatable between Python and C++, and Numpy ndarrays are not supported. In order to serialize these variable length inference results, I decided to flatten the numpy darrays into one dimensional vectors. \n",
    "\n",
    "The structure variable is a list of 32 bit unsigned integers which indicate the original shape of the arrays produced by the Vision Processing Unit.The inference variable is a list of 32 bit floats. \n",
    "\n",
    "The node can reshape the inference vector into the original arrays by using the structure vector as the original shape parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SceneSegmentationModule(object):\n",
      "\n",
      "    def action_loop(self):\n",
      "        self.timer.lap(\"Wait for Service\")\n",
      "        rospy.wait_for_service(\n",
      "            'model_server/modeling_service'\n",
      "            )\n",
      "        self.timer.time(\"Wait for Service\")\n",
      "        try:\n",
      "            self.timer.lap(\"Modeling Server\")\n",
      "            rospy.logdebug(f\"[{self.name.abv}] Service Requested.\")\n",
      "            req = String()\n",
      "            req.data = \"SEG\" #self.name.abv\n",
      "            response = self.model_request(req)\n",
      "            self.timer.time(\"Modeling Server\", name = \"MOD\")\n",
      "            self.inference = response.results\n",
      "            rospy.logdebug(\n",
      "                f\"[{self.name.abv}] Mask shape received: {self.inference.structure}\"\n",
      "                )\n",
      "            return self.inference\n",
      "\n",
      "        except rospy.ServiceException as e:\n",
      "            rospy.logerr(f\"[{self.name.abv}] Service call failed: {e}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dissect(\"action_loop\", SceneSegmentationModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main Loop\n",
    "The complete process is as follows:\n",
    "1. the Node checks for any updates to its parameters and begins logging its time.\n",
    "2. It then checks to see if there are any new images waiting for it at the model server.\n",
    "3. If there are new images, it makes a model request.Prior to making the request however it takes down its own \"waiting for image\" since it cannot simultaniously make a request and use these images.\n",
    "4. Following sucessfully receiving images it broadcasts the results to its subscribers. It does not update its request durring this time since while it is performing this action it cannot use any new images.\n",
    "5. After publishing its inference results it updates its flag to reflect that it is ready for a new image which will be delivered by the time the loop repetes itself and it requests a new inference from the model server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SceneSegmentationModule(object):\n",
      "\n",
      "    def loop(self):\n",
      "        rate = rospy.Rate(self.parameters.rate)\n",
      "        while not rospy.is_shutdown():\n",
      "            if self.parameters.updates == True:\n",
      "                self.parameters.update()\n",
      "                \n",
      "            # Setup timer. Note that this resets on every iteration. \n",
      "            # Future development we may want to move this so that we can \n",
      "            # compute averages.\n",
      "            \n",
      "            self.timer = ProcessTimer(abv = self.name.abv)\n",
      "            \n",
      "            # Check to see if the server has released a new image and \n",
      "            # if so, start new modeling request\n",
      "            \n",
      "            status = self.image_server.status(\"server\")\n",
      "            rospy.logdebug(\n",
      "                f\"[{self.name.abv}] Remote Image Server Status is: {status}\"\n",
      "                )\n",
      "            if status == True: \n",
      "                # Takes down image request flag while performing \n",
      "                # inference since inference time is not negligable\n",
      "                \n",
      "                self.image_server.update(False)\n",
      "                \n",
      "                my_status = self.image_server.status(\"me\")\n",
      "                rospy.logdebug(\n",
      "                    f\"[{self.name.abv}] Waiting Status: {my_status}\"\n",
      "                    )\n",
      "                # Create the image mask\n",
      "                try:\n",
      "                    mask = self.action_loop()\n",
      "                    self.pub.publish(mask)\n",
      "                    rospy.logdebug(f\"[{self.name.abv}] Mask Published\")\n",
      "                except:\n",
      "                    pass\n",
      "            # Update the image server to let it know we need a new image\n",
      "            \n",
      "            self.image_server.update(True)\n",
      "            rospy.logdebug(\n",
      "                \"[SEG] Waiting Status: %s\", \n",
      "                self.image_server.status(\"me\")\n",
      "                )\n",
      "            self.timer.time(\"total_runtime\")\n",
      "            rate.sleep()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dissect(\"loop\", SceneSegmentationModule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

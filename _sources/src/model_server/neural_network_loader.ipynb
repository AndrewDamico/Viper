{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NeuralNetworkLoader(object):\n",
      "    \"\"\"\n",
      "    \n",
      "    A NeuralNetworkLoader is a class object which loads a pretrained\n",
      "    model (architecture and weights) onto a initialized OpenVino\n",
      "    inference engine.\n",
      "    \n",
      "    Keyword Arguments:\n",
      "    \n",
      "    ie -- an Inference Engine instance set up in the parent node which \n",
      "    we will load this model to.\n",
      "    \n",
      "    ViperModel -- a instance of class ViperModel which contains the \n",
      "    models weights and the structure of the neural network.\n",
      "    \n",
      "    device -- the inference device to be used to predict on (i.e., \n",
      "    \"MYRIAD\", CPU, GPU, etc.)\n",
      "    \n",
      "    model_tag -- a three letter abbreviation used by the VIPER Logger\n",
      "    module which identifies log messages as originating from within this\n",
      "    modules code.\n",
      "    \n",
      "    model_name -- a logger attribute which identifies this model.\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, \n",
      "                ie: IECore, \n",
      "                viper_model: ViperModel,\n",
      "                device: str,\n",
      "                model_tag: str = \"M..\",\n",
      "                model_name: str = \"Model\",\n",
      "                *args,\n",
      "                **kwargs):\n",
      "        \n",
      "        # Creates our helper tools from our Viper Toolkkit such as \n",
      "        # the parameter manager, our log manager, and our timer.\n",
      "        self.setup_parameters(\n",
      "            model_name = model_name, \n",
      "            model_tag = model_tag)\n",
      "        \n",
      "        # Prepare this model for loading\n",
      "        self.setup_inference_engine(\n",
      "            ie = ie, \n",
      "            viper_model = viper_model, \n",
      "            device = device)\n",
      "\n",
      "        # Load the read network onto the initialized device.\n",
      "        self.load_inference_engine(device=device, ie = ie)\n",
      "        \n",
      "        # Retrieve the architecture of the model to load, including \n",
      "        # inputs and outputs and stores these on the parameter server\n",
      "        self.get_network_info()\n",
      "        \n",
      "        # Retrieves the image shapes for the input and output from the\n",
      "        # now loaded model and stores these on the parameter server\n",
      "        self.get_model_info()\n",
      "\n",
      "\n",
      "    def setup_parameters(self, model_name: str, model_tag: str):\n",
      "    \n",
      "        # Instantiate our logger tool naming these processes and\n",
      "        # setting the tag. The (\"XX.\") convention indicates this is a \n",
      "        # model and log messages are coming from within the \n",
      "        # model processing script and not the main node.\n",
      "        self.logger = Logger(\n",
      "            name = model_name, \n",
      "            tag = model_tag)\n",
      "        \n",
      "        # Instantiate our timer tool which will output the times of\n",
      "        # the processes within the model, and indicate that the \n",
      "        # process originated from within the model, and not the module.\n",
      "        self.timer = ProcessTimer(logger=self.logger)\n",
      "        \n",
      "        # Creates a parameter manager\n",
      "        self.NeuralNetworkParams = Parameters(logger=self.logger)\n",
      "        \n",
      "    def setup_inference_engine(self, ie: IECore, viper_model: ViperModel, device: str):\n",
      "\n",
      "        # Link the internal inference engine with the initialized engine\n",
      "        # and read the network architecture.\n",
      "        self._ie = ie\n",
      "        \n",
      "        # Load the Viper Model class object, which contains the address\n",
      "        # for the neural network architecture and well as the weights\n",
      "        # of the trained model.\n",
      "        self._net = ie.read_network(\n",
      "            model=viper_model.location,\n",
      "            weights=viper_model.weights\n",
      "            )\n",
      "\n",
      "    def load_inference_engine(self, device, ie):\n",
      "        \n",
      "        # Load the network architecture and weights into the initialized\n",
      "        # inference engine. We must indicate the device name which \n",
      "        # is passed through the main node.\n",
      "        self._exec_net = ie.load_network(\n",
      "            network = self._net,\n",
      "            device_name = device\n",
      "            )\n",
      "            \n",
      "    def get_network_info(self):\n",
      "        \n",
      "        # Set the input and output blobs\n",
      "        self._input_blob = next(iter(self._exec_net.input_info))\n",
      "        self._output_blob = next(iter(self._exec_net.outputs))\n",
      "\n",
      "        # Get the input shape\n",
      "        #self._input_shape = self._net.inputs[self._input_blob].shape\n",
      "        #self.logger.i(f'Input shape: {self._input_shape}')\n",
      "        \n",
      "        # Save these parameters to the parameter server\n",
      "        #self.NeuralNetworkParams.add(\n",
      "        #    Parameter(\n",
      "        #        name = \"Input_shape\",\n",
      "        #        value = self._input_shape,\n",
      "        #        dynamic = False))\n",
      "            \n",
      "        # Get the output shape\n",
      "        self._output_shape = self._net.outputs[self._output_blob].shape\n",
      "        self.logger.i(f'Output shape: {self._output_shape}')\n",
      "        \n",
      "        # Save these parameters to the parameter server\n",
      "        self.NeuralNetworkParams.add(\n",
      "            Parameter(\n",
      "                name=\"Output_shape\",\n",
      "                value=self._output_shape,\n",
      "                dynamic=False))\n",
      "                \n",
      "    def get_model_info(self):\n",
      "        \n",
      "        # Accesses the shape of the input layer and the output layer\n",
      "        self._input_key = list(self._exec_net.input_info)[0]\n",
      "        self._output_keys = list(self._exec_net.outputs.keys())\n",
      "        self._tensors = self._exec_net.input_info[self._input_key].tensor_desc\n",
      "        \n",
      "        # Saves the shapes to variables representing\n",
      "        self.n, self.c, self.h, self.w = self._tensors.dims\n",
      "        self.logger.i(f'Tensor shape (NCHW): ({self.n}, {self.c}, {self.h}, {self.w})')\n",
      "        \n",
      "        self.NeuralNetworkParams.add(\n",
      "            Parameter(\n",
      "                name=\"Input_height\",\n",
      "                value=self.h,\n",
      "                dynamic=False))\n",
      "\n",
      "        self.NeuralNetworkParams.add(\n",
      "            Parameter(\n",
      "                name=\"Input_width\",\n",
      "                value=self.w,\n",
      "                dynamic=False))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from viper_toolkit import Dissect\n",
    "from model_server import NeuralNetworkLoader\n",
    "lines = inspect.getsource(NeuralNetworkLoader)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ViperModel(object):\n",
      "    # A ViperModel contains the location of the model architecture\n",
      "    # and the model weights which are stored in the node package.\n",
      "    \n",
      "    def __init__(self, package_name, model_xml, weights_bin):\n",
      "        self.pkg = package_name\n",
      "        self.model = model_xml\n",
      "        self.weights = weights_bin\n",
      "        self.setup_model()\n",
      "        \n",
      "    def setup_model(self):\n",
      "        self.dir = roslib.packages.get_pkg_dir(self.pkg)\n",
      "        self.location = os.path.join(\n",
      "            self.dir, \n",
      "            self.model\n",
      "            )\n",
      "        self.weights = os.path.join(\n",
      "            self.dir, \n",
      "            self.weights\n",
      "            )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from model_server import ViperModel\n",
    "lines = inspect.getsource(ViperModel)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

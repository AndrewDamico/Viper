{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from viper_toolkit import Dissect\n",
    "from model_server import ViperModel, NeuralNetworkLoader\n",
    "from scene_segmentation_module import SceneSegmentationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene Segmentation Class\n",
    "\n",
    "The Scene Segmentation Model is a class of NeuralNetworkLoader models which performs scene segmentation on the image classifying the pixels in four classes:\n",
    "\n",
    "* Roadway\n",
    "* curb\n",
    "* Backgroun\n",
    "* Marker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Neural Network and the model weights found in the modules \"Model\" folder, the module first loads a ViperModel object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ViperModel(object):\n",
      "    # A ViperModel contains the location of the model architecture\n",
      "    # and the model weights which are stored in the node package.\n",
      "    \n",
      "    def __init__(self, package_name, model_xml, weights_bin):\n",
      "        self.pkg = package_name\n",
      "        self.model = model_xml\n",
      "        self.weights = weights_bin\n",
      "        self.setup_model()\n",
      "        \n",
      "    def setup_model(self):\n",
      "        self.dir = roslib.packages.get_pkg_dir(self.pkg)\n",
      "        self.location = os.path.join(\n",
      "            self.dir, \n",
      "            self.model\n",
      "            )\n",
      "        self.weights = os.path.join(\n",
      "            self.dir, \n",
      "            self.weights\n",
      "            )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = inspect.getsource(ViperModel)\n",
    "print (source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the class NeuralNetworkLoader\n",
    "When the VPU is initialized, the Model Server will provide the location of these parameters to the inference engine, as well as create a class object for this module called which I call a NeuralNetworkLoader. This object allows the model to be initialized at the time of the VPU instantiation, which is asyncronous to the instantiation of this module:\n",
    "\n",
    "***(Note: While I am providing the class definition here, the NeuralNetworkLoader Class is shared amongst all Model Nodes; I will break this down how this works in more detail on #TBA page)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NeuralNetworkLoader(object):\n",
      "    \"\"\"\n",
      "    \n",
      "    A NeuralNetworkLoader is a class object which loads a pretrained\n",
      "    model (architecture and weights) onto a initialized OpenVino\n",
      "    inference engine.\n",
      "    \n",
      "    Keyword Arguments:\n",
      "    \n",
      "    ie -- an Inference Engine instance set up in the parent node which \n",
      "    we will load this model to.\n",
      "    \n",
      "    ViperModel -- a instance of class ViperModel which contains the \n",
      "    models weights and the structure of the neural network.\n",
      "    \n",
      "    device -- the inference device to be used to predict on (i.e., \n",
      "    \"MYRIAD\", CPU, GPU, etc.)\n",
      "    \n",
      "    model_tag -- a three letter abbreviation used by the VIPER Logger\n",
      "    module which identifies log messages as originating from within this\n",
      "    modules code.\n",
      "    \n",
      "    model_name -- a logger attribute which identifies this model.\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, \n",
      "                ie: IECore, \n",
      "                viper_model: ViperModel,\n",
      "                device: str,\n",
      "                model_tag: str = \"M..\",\n",
      "                model_name: str = \"Model\",\n",
      "                *args,\n",
      "                **kwargs):\n",
      "        \n",
      "        # Creates our helper tools from our Viper Toolkkit such as \n",
      "        # the parameter manager, our log manager, and our timer.\n",
      "        self.setup_parameters(\n",
      "            model_name = model_name, \n",
      "            model_tag = model_tag)\n",
      "        \n",
      "        # Prepare this model for loading\n",
      "        self.setup_inference_engine(\n",
      "            ie = ie, \n",
      "            viper_model = viper_model, \n",
      "            device = device)\n",
      "\n",
      "        # Load the read network onto the initialized device.\n",
      "        self.load_inference_engine(device=device, ie = ie)\n",
      "        \n",
      "        # Retrieve the architecture of the model to load, including \n",
      "        # inputs and outputs and stores these on the parameter server\n",
      "        self.get_network_info()\n",
      "        \n",
      "        # Retrieves the image shapes for the input and output from the\n",
      "        # now loaded model and stores these on the parameter server\n",
      "        self.get_model_info()\n",
      "\n",
      "\n",
      "    def setup_parameters(self, model_name: str, model_tag: str):\n",
      "    \n",
      "        # Instantiate our logger tool naming these processes and\n",
      "        # setting the tag. The (\"XX.\") convention indicates this is a \n",
      "        # model and log messages are coming from within the \n",
      "        # model processing script and not the main node.\n",
      "        self.logger = Logger(\n",
      "            name = model_name, \n",
      "            tag = model_tag)\n",
      "        \n",
      "        # Instantiate our timer tool which will output the times of\n",
      "        # the processes within the model, and indicate that the \n",
      "        # process originated from within the model, and not the module.\n",
      "        self.timer = ProcessTimer(logger=self.logger)\n",
      "        \n",
      "        # Creates a parameter manager\n",
      "        self.NeuralNetworkParams = Parameters(logger=self.logger)\n",
      "        \n",
      "    def setup_inference_engine(self, ie: IECore, viper_model: ViperModel, device: str):\n",
      "\n",
      "        # Link the internal inference engine with the initialized engine\n",
      "        # and read the network architecture.\n",
      "        self._ie = ie\n",
      "        \n",
      "        # Load the Viper Model class object, which contains the address\n",
      "        # for the neural network architecture and well as the weights\n",
      "        # of the trained model.\n",
      "        self._net = ie.read_network(\n",
      "            model=viper_model.location,\n",
      "            weights=viper_model.weights\n",
      "            )\n",
      "\n",
      "    def load_inference_engine(self, device, ie):\n",
      "        \n",
      "        # Load the network architecture and weights into the initialized\n",
      "        # inference engine. We must indicate the device name which \n",
      "        # is passed through the main node.\n",
      "        self._exec_net = ie.load_network(\n",
      "            network = self._net,\n",
      "            device_name = device\n",
      "            )\n",
      "            \n",
      "    def get_network_info(self):\n",
      "        \n",
      "        # Set the input and output blobs\n",
      "        self._input_blob = next(iter(self._exec_net.input_info))\n",
      "        self._output_blob = next(iter(self._exec_net.outputs))\n",
      "\n",
      "        # Get the input shape\n",
      "        #self._input_shape = self._net.inputs[self._input_blob].shape\n",
      "        #self.logger.i(f'Input shape: {self._input_shape}')\n",
      "        \n",
      "        # Save these parameters to the parameter server\n",
      "        #self.NeuralNetworkParams.add(\n",
      "        #    Parameter(\n",
      "        #        name = \"Input_shape\",\n",
      "        #        value = self._input_shape,\n",
      "        #        dynamic = False))\n",
      "            \n",
      "        # Get the output shape\n",
      "        self._output_shape = self._net.outputs[self._output_blob].shape\n",
      "        self.logger.i(f'Output shape: {self._output_shape}')\n",
      "        \n",
      "        # Save these parameters to the parameter server\n",
      "        self.NeuralNetworkParams.add(\n",
      "            Parameter(\n",
      "                name=\"Output_shape\",\n",
      "                value=self._output_shape,\n",
      "                dynamic=False))\n",
      "                \n",
      "    def get_model_info(self):\n",
      "        \n",
      "        # Accesses the shape of the input layer and the output layer\n",
      "        self._input_key = list(self._exec_net.input_info)[0]\n",
      "        self._output_keys = list(self._exec_net.outputs.keys())\n",
      "        self._tensors = self._exec_net.input_info[self._input_key].tensor_desc\n",
      "        \n",
      "        # Saves the shapes to variables representing\n",
      "        self.n, self.c, self.h, self.w = self._tensors.dims\n",
      "        self.logger.i(f'Tensor shape (NCHW): ({self.n}, {self.c}, {self.h}, {self.w})')\n",
      "        \n",
      "        self.NeuralNetworkParams.add(\n",
      "            Parameter(\n",
      "                name=\"Input_height\",\n",
      "                value=self.h,\n",
      "                dynamic=False))\n",
      "\n",
      "        self.NeuralNetworkParams.add(\n",
      "            Parameter(\n",
      "                name=\"Input_width\",\n",
      "                value=self.w,\n",
      "                dynamic=False))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = inspect.getsource(NeuralNetworkLoader)\n",
    "print (source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of this is that the inference engine object is initiated once, and all models are loaded to the inference engine object at initialization. This module then instantiates a SeceneSegmentationModel, which is a child class of the NeuralNetworkLoader already instantiated on behalf of this module. We allow this module to inherit all methods and properties of the parent class.\n",
    "\n",
    "In effect, the class object that was initiated prior to this modules initialization can then be \"passed on\" to this module as if it were this module which had instantiated this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Segmentation Model\n",
    "The SceneSegmentationModel is a class object of type NeuralNetworkLoader, and contains the methods particular to the performance of Scene Segmentation. It contains two class methods:\n",
    "* export_parameters() which exports the shape of the model specificly needed by this model\n",
    "* run_scene_segmentation() which is the method by which the image is transformed and passed to the inference engine for prediction. \n",
    "\n",
    "After sucessfully invoking this method an image mask is returned with each pixel being classified as one of the four classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SceneSegmentationModel(NeuralNetworkLoader):\n",
      "    \"\"\"\n",
      "    \n",
      "    A SceneSegmentationModel is a class object which uses a Convolutional\n",
      "    Neural Network (CNN) to classify  every pixel within an image as a \n",
      "    member of a certain class (segments the image). In this  pytorch \n",
      "    pretrained model we are predicting on 4 classes: \n",
      "        (a) Roadway, (b) Curb, (c) Background, and (d) marker. \n",
      "    \n",
      "    The model specifications can be found at: \n",
      "    https://docs.openvino.ai/2018_R5/_docs_Transportation_segmentation_curbs_release1_caffe_desc_road_segmentation_adas_0001.html\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, *args, **kwargs):\n",
      "        super().__init__(*args, **kwargs)\n",
      "\n",
      "    def export_parameters(export_state=True, **kwargs):\n",
      "        # Exports parameters sent to this function for debugging \n",
      "        # purposes, and then turns off function after export_state=False\n",
      "        # is received.\n",
      "        self.export_state = False\n",
      "        \n",
      "        for arg in kwargs:\n",
      "            self.parameters.add(\n",
      "                Parameter(\n",
      "                    name = arg,\n",
      "                    value = kwargs[arg],\n",
      "                    dynamic = False))\n",
      "\n",
      "        self.export_state = export_state\n",
      "\n",
      "    def run_scene_segmentation(self, frame):\n",
      "\n",
      "        # The default ROS image is BGR color, however the model is\n",
      "        # expecting RGB, so we will need to convert this first.\n",
      "        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
      "\n",
      "        # We will now attempt to resize the image to fit the model input\n",
      "        #try:\n",
      "        input_img = cv2.resize(rgb_image, (self.w, self.h))\n",
      "        rospy.loginfo(\"resized\")\n",
      "            #self.logger.d(f\"Resized Shape: {input_img.shape}\")\n",
      "        #except:\n",
      "            #self.logger.e(f\"Cannot resize image to shape ({self.w}, {self.h})\") \n",
      "            #return\n",
      "            \n",
      "        if self.export_state: \n",
      "            self.export_parameters(resized_shape = input_img.shape)\n",
      "\n",
      "        # We need to wrangle the image from into the NCHW format.\n",
      "        #try:    \n",
      "        transposed_img = np.expand_dims(\n",
      "                a = input_img.transpose(2, 0, 1),\n",
      "                axis = 0)\n",
      "        rospy.loginfo(\"transposed\")\n",
      "            #self.logger.d(f\"Transposed Shape: {transposed_img.shape}\")\n",
      "        #except:\n",
      "        #    self.logger.e(\"Error converting to NCHW format\")\n",
      "        #    return\n",
      "        \n",
      "        if self.export_state: \n",
      "                self.export_parameters(transposed_shape=transposed_img.shape)\n",
      "        \n",
      "\n",
      "        # We will now perform inference on the input object using the\n",
      "        # inference engine we loaded to the Visual Processing Unit\n",
      "        results = self._exec_net.infer(\n",
      "            inputs = {self._input_layer: transposed_img}\n",
      "            )\n",
      "        rospy.loginfo(\"infered\")\n",
      "        # Extract the inference blob from the results array\n",
      "        result_ir = results[self._output_blob]\n",
      "        \n",
      "        # We then compute the maximum value along axis 1 indicating\n",
      "        # the max likelyhood class for which that pixel belongs, and\n",
      "        # return this classification map of the original image.\n",
      "        mask = np.argmax(\n",
      "            a = result_ir, \n",
      "            axis=1)\n",
      "        \n",
      "        # We export the successful shape and then turn off exporting.\n",
      "        if self.export_state:\n",
      "            self.export_parameters(mask_shape=mask.shape, export_state=False)\n",
      "            \n",
      "        self.logger.i(f\"Returning shape: {mask.shape}\")\n",
      "\n",
      "        return mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = inspect.getsource(SceneSegmentationModel)\n",
    "print (source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

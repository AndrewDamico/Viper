
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5. Model Server &#8212; Viper Vision Inference Processing Endogenous (Edge) Robot</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "https://github.com/AndrewDamico/viper");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.2. Neural Network Loader" href="neural_network_loader.html" />
    <link rel="prev" title="4.3. Sample Subscriber Nodes" href="../viper_toolkit/sample_subscriber.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/viper_device.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Viper Vision Inference Processing Endogenous (Edge) Robot</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction.html">
   Vision Inference Processing Endogenous Robot
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../readme.html">
   1. The ROS VIPER Library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../docs/communication_diagram.html">
   2. Viper Communication Diagram
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../docs/process_diagram.html">
   3. Viper Data Process Diagram
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../docs/ros_structure.html">
   4. Robot OS (ROS)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/sample_publisher.html">
     4.2. Sample Publisher Nodes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/sample_subscriber.html">
     4.3. Sample Subscriber Nodes
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Packages
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   5. Model Server
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="neural_network_loader.html">
     5.2. Neural Network Loader
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../image_server/readme.html">
   6. Image Server
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../image_server/image_server.html">
     6.1. Image Server Node
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../image_server/image_server_client.html">
     6.2. Image Server Client
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../scene_segmentation_module/readme.html">
   7. Scene Segmentation Module
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene_segmentation_module/scene_segmentation_module.html">
     7.5. Scene Segmentation Module Process
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene_segmentation_module/scene_segmentation_model.html">
     7.6. Scene Segmentation Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene_segmentation_module/example.html">
     7.7. Scene Segmentation Example
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../pose_detection_module/readme.html">
   8. Pose Detection Module
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../pose_detection_module/pose_detection_module.html">
     8.1. Pose Detection Module
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pose_detection_module/pose_detection_model.html">
     8.2. Pose Detection Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pose_detection_module/example.html">
     8.3. Pose Detection Example
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../augmented_vr_module/readme.html">
   9. Augmented VR Module
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../augmented_vr_module/augmented_vr_module.html">
     9.1. Augmented VR Module
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../viper_toolkit/readme.html">
   10. Viper Toolkit
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/dissector.html">
     10.1. Class Dissector
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/logger.html">
     10.2. Logger Module
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/name_manager.html">
     10.3. Name Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/parameter_manager.html">
     10.4. Parameter Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../viper_toolkit/process_timer.html">
     10.5. Process Timer
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hardware
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../docs/Hardware.html">
   Hardware Configuration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.raspberrypi.com/">
   Raspberry Pi
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Software
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://mate-desktop.org/">
   Mate Desktop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.ubuntu.com">
   Ubuntu
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/neural-compute-stick/overview.html">
   Intel Neural Compute Stick 2
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/src/model_server/model_server.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AndrewDamico/viper"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/AndrewDamico/viper/issues/new?title=Issue%20on%20page%20%2Fsrc/model_server/model_server.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/AndrewDamico/viper/edit/main/https://andrewdamico.github.io/viper/src/model_server/model_server.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AndrewDamico/viper/main?urlpath=tree/https://andrewdamico.github.io/viper/src/model_server/model_server.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-model-server-module">
   5.1. The Model Server Module
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="model-server">
<h1><span class="section-number">5. </span>Model Server<a class="headerlink" href="#model-server" title="Permalink to this headline">¬∂</a></h1>
<p>The Intel Neural Compute Stick 2 is a compact and yet powerful Vision Processing Unit (VPU) which is optimized to perform the complex matrix calculations required for convolutional neural networks. Similar to a GPU, the VPU is engineered specifically for computer vision inference on images and videos.</p>
<p>The VPU is initalized with the network structure of the neural networks as well as the weights; these networks are then allocated space on the device. Total time to initialize a network is approximately 30 seconds, however once it has been initalized successive inference on a loaded model is processed in milliseconds.</p>
<p>In order for multiple modules to make use of the VPU, it is therefor desirable for the device to be initialized once with multiple models.</p>
<p>To accomplish this I have engineered the Model Server. The Model Server is responsable for initializing the VPU device, and registering the various Networks with the device. The Model Server then makes an Inference Service API available to the modules. If a module needs inference performed, it uses the Model Server API to provide the server with the kind of model needed, as well as the image requirements. The model server then uses its most recent image and performs inference on the VPU, returning the results to the model module where additional  processing can take place.</p>
<p>In order to receive the most recent images, the Modeling Server offers a second API endpoint for the Image Server Module. A limitation of ROS Noetic is that a service node cannot subscribe to other nodes like normal nodes can; this is because the service node needs to continually monitor the API requests. As such, the Model Server cannot obtain images on its own outside of an API call. In order to minimize the bandwidth and the duplication of images, the Image Server offers a kind of ‚Äúreverse‚Äù service. Rather than acting as an API endpoint, the Image Server makes a service call to the Model Server requesting to give it an image via the Image Fetching Service offered by the model server. The Model Server then accepts that image, and the Image Server carries on with the management of the Image flags and requests for the nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">viper_toolkit</span> <span class="k">import</span> <span class="n">Dissect</span>
<span class="kn">import</span> <span class="nn">inspect</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-model-server-module">
<h2><span class="section-number">5.1. </span>The Model Server Module<a class="headerlink" href="#the-model-server-module" title="Permalink to this headline">¬∂</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scripts</span> <span class="k">import</span> <span class="n">modelserver</span>
<span class="kn">from</span> <span class="nn">scripts.modelserver</span> <span class="k">import</span> <span class="n">ModelServer</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">ModelServer</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class ModelServer(object):
    
    def __init__(self):
        self.setup_ros()
        self.image = Image()
        self.setup_inference_engine()
        self.setup_models()
        self.loop()
        
    def setup_ros(self):
        rospy.init_node(&#39;model_server&#39;, log_level=rospy.DEBUG)
        self.setup_parameters()
        self.logger.i(&#39;Model Server Initialized&#39;)
    
    def setup_parameters(self):
        # Instantiates the Name Manager and Logger to standardize the 
        # nodes name and abreviation throughout the addon modules
        self.name = NameManager()
        self.logger = Logger(self.name)
        
        # Creates an instance of the organizer I will be using for 
        # my parameters. This allows for dynamic updatign accross nodes
        self.parameters = ParameterManager()
        
        # Sets this module to allow for dynamic updating
        self.parameters.add(
            Parameter(
                name=&quot;updates&quot;, 
                target=f&quot;{self.name.name}/dynamic&quot;,
                default=True, 
                dynamic=True))
                
        # Searches for the code of the Pode Detection Module. If the 
        # the module cannot be found, the default of PDM will be used
        # and will be updated if the modules code changes when it comes
        # online. This code is used to tell the inference engine which
        # neural network to use for inference.
        self.parameters.add(
            Parameter(
                name=&quot;PoseDetection_abv&quot;, 
                target=rospy.search_param(
                    &#39;pose_detection_module/abv&#39;), 
                default=&quot;PDM&quot;, 
                dynamic=True))
        
        # Searches for the code of the Scene Segmentation module. Will
        # use default value if not found, and will update dynamically 
        # if the code later becomes available.
        self.parameters.add(
            Parameter(
                name = &quot;SceneSegmentation_abv&quot;, 
                target = rospy.search_param(
                    &#39;scene_segmentation_module/abv&#39;), 
                default = &quot;SEG&quot;, 
                dynamic = True))

    def setup_inference_engine(self):
        
        # Sets up the OpenVino Inference Engine core to handle
        # multiple models
        self.ie = IECore()
        self.logger.i(&quot;IECore Online&quot;)

    def setup_models(self):
        
        # Create a dictionary of models. The specific model will be
        # be identified at the time of inference.
        self.models = {}
        
        # Initializes the models. All models will be loaded to the 
        # Neural Compute Stick Vision Processing Unit.
        self.setup_pose_detector(device=&quot;MYRIAD&quot;)
        self.setup_scene_segmentor(device=&quot;MYRIAD&quot;)

    def setup_pose_detector(self, device):
        
        # Initializes a viper model pointing to the Artificial Neural
        # Network Architecture and the weights.
        pose_detector = ViperModel(
            package_name = &#39;pose_detection_module&#39;,
            model_xml = &#39;model/human-pose-estimation-0001.xml&#39;,
            weights_bin = &#39;model/human-pose-estimation-0001.bin&#39;
            )
        
        # These model paramters are then loaded into the Intel
        # Nerual Compute Stick inference engine. 
        self.pose_engine = PoseDetectionModel(
            ie = self.ie,
            viper_model = pose_detector,
            device = device,
            model_tag = &quot;PD.&quot;,
            model_name = &quot;PoseDetectionModel&quot;
            )
        
        # The path to the inference function of the model is 
        # saved in the model dictionary. This will be called when
        # a node makes a service API request via its access point.
        
        #self.models[f&#39;{self.parameters.PoseDetection_abv}&#39;] \
        #    = self.pose_engine.run_pose_estimation
            
        self.models[&quot;POS&quot;] = self.pose_engine.run_pose_estimation
        self.logger.i(&#39;Pose Detection Model Loaded&#39;)

    def setup_scene_segmentor(self, device):
        
        # Here we set up the Scene Segmentation model.
        scene_segmentor = ViperModel(
            package_name = &quot;scene_segmentation_module&quot;,
            model_xml = &#39;model/road-segmentation-adas-0001.xml&#39;,
            weights_bin = &#39;model/road-segmentation-adas-0001.bin&#39;
            )
            
        # We load the model to the same device, which had been 
        # already been initialized at the server startup. This allows
        # us to add and remove models as needed, without shutting
        # the VPU down, while also sharing the device.
        self.scene_segmentor = SceneSegmentationModel(
            ie = self.ie,
            viper_model = scene_segmentor,
            device = device,
            model_tag = &quot;SD.&quot;,
            model_name = &quot;SceneSegmentationModel&quot;
            )
        
        # We load the Scene Segmentation model to the model dictionary.
        
        #self.models[f&#39;{self.parameters.SceneSegmentation_abv}&#39;] \
        #    = self.scene_segmentor.run_scene_segmentation
        
        self.models[&quot;SEG&quot;] = self.scene_segmentor.run_scene_segmentation
        self.logger.i(&quot;Scene Segmentor Loaded&quot;)

    def handle_model_rqst(self, request):
        
        # This function is the API callback. Upon receiving a proper
        # request via the service endpoint, the requested model
        # is saved as &#39;model&#39;
        
        self.process_timer.lap(&quot;Modeling Service&quot;)
        self.logger.i(&quot;Modeling Request Received&quot;)
        model = request.model.data
        print(model)
        # The image which we will be performing inference on is 
        # is converted from a ROS message to a  numpy image array.
        try:
            bridge = CvBridge()
            image = bridge.imgmsg_to_cv2(
                self.image,
                desired_encoding=&quot;rgb8&quot;
                )
                
            #self.logger.i(f&#39;Image reshaped to: {np.shape(image)}&#39;)
            
        except CvBridgeError as cv_error:
            print(&quot;ERRRRRRERERRROROR&quot;)
            self.logger.e(f&#39;&quot;CvBridge Error: {cv_error}&#39;)
            
            print(cv_error)
            
            #If this process fails we will need to return to try 
            # on the next loop. This sometimes happens due to 
            # packet loss.
            
            return
            
        # We use the resulting image to perform inference.
        self.process_timer.lap(model)
        
        try:
            results = self.models[model](frame=image)
            print(results)
        except:
            self.logger.e(f&quot;Error modeling {model}&quot;)
            return
            
        self.process_timer.time(model)
        self.process_timer.lap(f&#39;Flatten {model}&#39;)
        
        # We need to serialize all of the inferences accross models and
        # accross results in order to format them in a standard
        # and consistent message packet.
        try:
            packet = self.flatten_inference(results)
        except:
            self.logger.e(f&quot;Error flattening {model}&quot;)
            
            return
            
        self.process_timer.time(f&#39;Flatten {model}&#39;)
        self.process_timer.time(&quot;Modeling Service&quot;)
        
        # Upon success we will return the message packet to the API for
        # delivery to the client.
        
        return packet

    def handle_fetch_rqst(self, request):
        
        # This is the Service API callback for the Image Server Service.
        # Upon receiving a request from the model server to deliver
        # an image, this process saves that image message (self.image).
        #self.process_timer.lap(&quot;Image Service&quot;)
        #self.logger.i(&quot;Image request received&quot;)
        
        try:
            self.image = request.image
            receipt = True
        except:
            receipt = False
            
        #self.process_timer.time(&quot;Image Service&quot;)
        # We then respond with a message indicating the outcome of the
        # request.
        
        return ImageRequestResponse(Bool(receipt))

    def flatten_inference(self, results_array):
        
        # This function converts our results array into a 
        # [std_msgs.msg/int32] array containing the ndarry shape and 
        # a [std_msgs.msg/float32] array containing the flattened array.
        
        # Load the InferenceResults Template
        packet = InferenceResults()
        print(results_array)
        try:
            structure = results_array.shape
            rospy.logdebug(&quot;[MOD] mask structure: %s&quot;,structure)
            structure = list(structure) 
            structure = np.array(structure).astype(np.int32)
            structure = list(structure)
            rospy.logdebug(&quot;[MOD] Converted params: %s&quot;, structure)
            packet.structure = structure # [Int32]
            rospy.logdebug(&quot;[MOD] Structure sent: %s&quot;,packet.structure)
            
        except:
            rospy.logerr(&quot;[MOD] Cannot save mask structure.&quot;)
            
        try:
            inferences = np.array(list(results_array.flatten()))
            packet.inferences = inferences # [float32]
            
        except:
            rospy.logerr(&quot;[MOD] Cannot save Inference shape.&quot;)
            rospy.logerr(&quot;[MOD] Inference shape is: %s&quot;, inferences.shape)
        print(packet)
        return packet

    def loop(self):
        
        while not rospy.is_shutdown(): 
            
            # This function will keep our parameters dynamically updated
            # in case that they change as other nodes come online
            # or offile. Parameters marked as &quot;updates = True&quot; will
            # update accordingly. 
            
            if self.parameters.updates == True:
                    self.parameters.update()
            
            # This function Initializes my custom process timer module, 
            # which computes the time between any two proceses by name.
            # It also connects with my custom &quot;Logger&quot; module, the 
            # &quot;Parameter&quot; module, and my &quot;NameManager&quot; module to help me
            # track information accross Nodes.
            
            self.process_timer = ProcessTimer(logger = self.logger)
            
            # This is the API access point for the Image Server. The
            # client submits an Image Request message, which contains
            # an ROS Image message. In return they will receive a Bool
            # indicating the outcome of the request.
            
            self.image_fetching_service = rospy.Service(
                &#39;model_server/image_fetching_service&#39;, 
                ImageRequest, 
                self.handle_fetch_rqst
                )
            #self.logger.i(&quot;Image Fetching Service Online&quot;)
            
            # This is the API access point for the Modeling Service. The
            # client submits a three letter model code, and the service
            # will use the most recent image to perform inference. It
            # then returns two arrays; one array &#39;Structure&#39; contains 
            # the shape of the original inference output, and a second
            # array &quot;Inferences&quot; contains the flattened 1-Dimnesional 
            # array.
            
            self.modeling_service = rospy.Service(
                &#39;model_server/modeling_service&#39;, 
                ModelRequest, 
                self.handle_model_rqst
                )
                
            #self.logger.i(&quot;Modeling Service Online&quot;)

            #self.logger.i(&quot;Model Server Online&quot;)
            
            # Rospy.spin() keeps our kernal active during times of 
            # inactivity.
            
            rospy.spin()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">model_server.srv</span> <span class="k">import</span> <span class="n">ImageRequest</span><span class="p">,</span> <span class="n">ImageRequestResponse</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">var</span> <span class="o">=</span> <span class="n">ImageRequest</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ImageRequestResponse</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>status: 
  data: False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">model_server.msg</span> <span class="k">import</span> <span class="n">InferenceResults</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">InferenceResults</span><span class="p">())</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">f</span><span class="s1">&#39;Structure Datatype: {type(InferenceResults().structure)}&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">f</span><span class="s1">&#39;Inferences Datatype: {type(InferenceResults().inferences)}&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>structure: []
inferences: []
Structure Datatype: &lt;class &#39;list&#39;&gt;
Inferences Datatype: &lt;class &#39;list&#39;&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./src/model_server"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../viper_toolkit/sample_subscriber.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4.3. </span>Sample Subscriber Nodes</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="neural_network_loader.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.2. </span>Neural Network Loader</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Andrew Damico<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>